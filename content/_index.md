+++
title = "Boden Moraski"
description = "Hi, I'm Boden! This is my website -- my own personal simulacrum. Feel free to browse about here, or visit my contact or experience pages."
hero_image = "/Static-Website-BodenMoraski/images/hero.jpg"
+++

I have a range of interests, but I'm most fundamentally concerned with why (and how!) we make decisions (especially moral decisions) and how we can make the future better. 

## Current Work

Right now I'm primarily interested in [AI Safety](https://www.anthropic.com/news/core-views-on-ai-safety). Technically, I've been exploring [scalable oversight](https://bluedot.org/blog/scalable-oversight-intro), [risk and capabilities benchmarking](https://ai-safety-atlas.com/chapters/05), and [prosaic alignment](https://aisafety.info/questions/89LM/What-is-prosaic-alignment). I also believe that governance, advocacy, and community-building in AI Safety are all crucial to support and complement these research directions.

I'm also interested in [ethical frameworks](https://aese.psu.edu/teachag/curriculum/modules/bioethics-1/what-are-ethical-frameworks) and how they interact and arise in both biological and artificial systems. I personally tend to operate through an ever-evolving amalgam of [Virtue Ethics](https://plato.stanford.edu/entries/ethics-virtue/), [Rationalism](https://plato.stanford.edu/entries/rationalism-empiricism), [Confucianism](https://plato.stanford.edu/entries/confucius), and [Consequentialism](https://plato.stanford.edu/entries/consequentialism/#ClasUtil), predominantly in the context of [Longtermism](https://www.effectivealtruism.org/articles/longtermism).

[View my projects and experience â†’](/experience/)

## Other Interests

Adjacent to these interests and work, I am interested in and have previously engaged with [social simulation and modeling](https://en.wikipedia.org/wiki/Social_simulation), especially around [political polarization](https://www.populismstudies.org/Vocabulary/political-polarization), [moral uncertainty](https://plato.stanford.edu/entries/moral-decision-uncertainty/), [theodicies](https://plato.stanford.edu/entries/theodicies), [behavioral economics](https://www.investopedia.com/terms/b/behavioraleconomics.asp#:~:text=Behavioral%20economics%20is%20the%20study%20of%20psychology%20that%20analyzes%20the,%2C%20discrimination%2C%20and%20herd%20mentality.), and [information theory](https://www.britannica.com/science/information-theory). I always welcome hearing from anyone interested in these topics.

## Get in Touch

I'm always interested in connecting with fellow researchers, builders, and anyone passionate about AI, ethics, or education. [Reach out here](/contact/) or email me at bodenmoraski [at] gmail.com.
